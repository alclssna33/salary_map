# -*- coding: utf-8 -*-
"""
ë©”ë””ê²Œì´íŠ¸ êµ¬ì¸ ê³µê³  í¬ë¡¤ëŸ¬ - Phase 3 í…ŒìŠ¤íŠ¸
ëŒ€ìƒ: https://www.medigate.net/recruit
ì „ëµ: ê° ê³µê³  í–‰ì˜ ìì‹ ìš”ì†Œ ìˆœì„œ(Index) ê¸°ë°˜ ì¶”ì¶œ
"""

import sys
import io
import time
import json
import re
from datetime import datetime

# Windows cp949 í™˜ê²½ì—ì„œ UTF-8 ì¶œë ¥ ê°•ì œ ì„¤ì •
if sys.stdout.encoding.lower() != "utf-8":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

LOGIN_ID = "bassdoctor"
LOGIN_PW = "!q2w3e4r5t"
BASE_URL = "https://new.medigate.net"
RECRUIT_URL = "https://new.medigate.net/recruit/list"
TARGET_COUNT = 10


def build_unique_key(hospital_name: str, region: str, start_date_str: str) -> str:
    """
    ì¤‘ë³µ íŒë‹¨ìš© ë³µí•© ê³ ìœ  í‚¤ ìƒì„±.
    ê¸°ì¤€: ë³‘ì›ëª… + ì§€ì—­ + ì‹œì‘ ì—°ì›”(YYYY-MM)
    - ì œëª©(title)ì€ ì¤‘ë³µ íŒë‹¨ì—ì„œ ì™„ì „íˆ ì œì™¸
    - ë‹¬ì´ ë°”ë€Œë©´ ìƒˆ êµ¬ì¸ ìˆ˜ìš”ë¡œ ê°„ì£¼í•˜ì—¬ ë‹¤ë¥¸ í‚¤ë¡œ ì²˜ë¦¬
    """
    # ì‹œì‘ì¼ "(MM/DD ì‹œì‘)" ì—ì„œ MM ì¶”ì¶œ â†’ ì˜¬í•´ YYYY-MM êµ¬ì„±
    year_month = datetime.now().strftime("%Y-%m")   # ê¸°ë³¸ê°’: í¬ë¡¤ë§ ë‹¹ì›”
    if start_date_str:
        m = re.search(r'\((\d{2})/\d{2}', start_date_str)
        if m:
            month = m.group(1)
            year = datetime.now().strftime("%Y")
            year_month = f"{year}-{month}"
    return f"{hospital_name}||{region}||{year_month}"


def get_driver():
    """Chrome WebDriver ì´ˆê¸°í™”"""
    options = Options()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options,
    )
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    return driver


def login(driver):
    """ë©”ë””ê²Œì´íŠ¸ ë¡œê·¸ì¸ (new.medigate.net ê¸°ì¤€)"""
    print("â–¶ ë©”ì¸ í˜ì´ì§€ ì´ë™ ì¤‘...")
    driver.get(BASE_URL)
    time.sleep(3)

    wait = WebDriverWait(driver, 20)

    # ID ì…ë ¥ - ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„
    id_selectors = [
        "input[name='usrIdT']",
        "input[type='text'][name*='id']",
        "input[placeholder*='ì•„ì´ë””']",
        "input[placeholder*='ID']",
        "#usrIdT",
    ]
    id_input = None
    for sel in id_selectors:
        try:
            id_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, sel)))
            print(f"â–¶ ID ì…ë ¥ì°½ ë°œê²¬: {sel}")
            break
        except Exception:
            continue

    if not id_input:
        # í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•´ì„œ êµ¬ì¡° í™•ì¸
        with open("C:/medigate_dev/debug_page.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        raise RuntimeError(f"ID ì…ë ¥ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. í˜„ì¬ URL: {driver.current_url}\në””ë²„ê·¸ íŒŒì¼: C:/medigate_dev/debug_page.html")

    id_input.clear()
    id_input.send_keys(LOGIN_ID)

    # PW ì…ë ¥ - ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„
    pw_selectors = [
        "input[name='usrPasswdT']",
        "input[type='password']",
        "input[placeholder*='ë¹„ë°€ë²ˆí˜¸']",
        "#usrPasswdT",
    ]
    pw_input = None
    for sel in pw_selectors:
        try:
            pw_input = driver.find_element(By.CSS_SELECTOR, sel)
            print(f"â–¶ PW ì…ë ¥ì°½ ë°œê²¬: {sel}")
            break
        except Exception:
            continue

    if not pw_input:
        raise RuntimeError("ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    pw_input.clear()
    pw_input.send_keys(LOGIN_PW)

    # ë¡œê·¸ì¸ ë²„íŠ¼ - ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„
    btn_selectors = [
        "button[onclick*='checkLoginForm']",
        "button[type='submit']",
        "input[type='submit']",
        "button.login-btn",
        "button:contains('ë¡œê·¸ì¸')",
    ]
    login_btn = None
    for sel in btn_selectors:
        try:
            login_btn = driver.find_element(By.CSS_SELECTOR, sel)
            print(f"â–¶ ë¡œê·¸ì¸ ë²„íŠ¼ ë°œê²¬: {sel}")
            break
        except Exception:
            continue

    if not login_btn:
        # Enter í‚¤ë¡œ í¼ ì œì¶œ ì‹œë„
        from selenium.webdriver.common.keys import Keys
        pw_input.send_keys(Keys.RETURN)
        print("â–¶ Enter í‚¤ë¡œ ë¡œê·¸ì¸ ì‹œë„...")
    else:
        login_btn.click()
        print("â–¶ ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")

    print("â–¶ ë¡œê·¸ì¸ ì„¸ì…˜ ëŒ€ê¸° ì¤‘...")
    time.sleep(5)
    print(f"â–¶ í˜„ì¬ URL: {driver.current_url}")


def parse_items_from_source(page_source):
    """
    BeautifulSoupìœ¼ë¡œ ê³µê³  í–‰ íŒŒì‹±
    children[0]=1ì—´(ë³‘ì›), [1]=2ì—´(ì œëª©), [2]=3ì—´(ê³ ìš©), [3]=4ì—´(ë‚ ì§œ)
    """
    soup = BeautifulSoup(page_source, "html.parser")
    results = []
    title_spans = soup.select("span.my-80pqzf")
    if not title_spans:
        print("  âš  span.my-80pqzf ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return results

    # ì¤‘ë³µ íŒë‹¨: ë³‘ì›ëª… + ì§€ì—­ + ë“±ë¡ì›”(YYYY-MM) ë³µí•© í‚¤
    # ì œëª©(title)ì€ ì¤‘ë³µ íŒë‹¨ ê¸°ì¤€ì—ì„œ ì™„ì „íˆ ì œì™¸
    seen_keys = set()

    for title_span in title_spans:
        title_text = title_span.get_text(strip=True)
        if not title_text:
            continue

        col2 = title_span.find_parent("button")
        if not col2:
            continue
        row = col2.parent
        children = [c for c in row.children if hasattr(c, "name") and c.name]
        if len(children) < 4:
            continue

        col1 = children[0]
        col3 = children[2]
        col4 = children[3]

        # 1ì—´: ë³‘ì›ëª…, ë³‘ì›íƒ€ì…
        hospital_name_tag = col1.select_one("span.my-10e3t97")
        hospital_type_tag = col1.select_one("span.my-1cqarh6")
        hospital_name = hospital_name_tag.get_text(strip=True) if hospital_name_tag else ""
        hospital_type = hospital_type_tag.get_text(strip=True) if hospital_type_tag else ""

        # 2ì—´: ì œëª©, ì „ê³µ
        title = title_text
        specialty_tags = col2.select("span.my-1n83qxm")
        specialties = [t.get_text(strip=True) for t in specialty_tags if t.get_text(strip=True)]

        # ê³µê³  URL
        source_url = ""
        source_id = ""
        parent_a = col2.find_parent("a")
        if parent_a and parent_a.get("href"):
            href = parent_a["href"]
            source_url = href if href.startswith("http") else BASE_URL + href
            m = re.search(r"/recruit/(\d+)", source_url)
            if m:
                source_id = m.group(1)

        # 3ì—´: ê³ ìš©í˜•íƒœ, ì§€ì—­
        employment_tag = col3.select_one("span.my-10e3t97")
        location_tag = col3.select_one("span.my-1cqarh6")
        employment_type = employment_tag.get_text(strip=True) if employment_tag else ""
        location = location_tag.get_text(strip=True) if location_tag else ""

        # 4ì—´: ë§ˆê°ì¼, ì‹œì‘ì¼
        col4_children = [c for c in col4.children if hasattr(c, "name") and c.name]
        deadline = col4_children[0].get_text(strip=True) if len(col4_children) > 0 else ""
        start_date = col4_children[1].get_text(strip=True) if len(col4_children) > 1 else ""

        # â”€â”€ ë³µí•© ê³ ìœ  í‚¤ ìƒì„± ë° ì¤‘ë³µ ì²´í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        unique_key = build_unique_key(hospital_name, location, start_date)
        if unique_key in seen_keys:
            print(f"  [SKIP ì¤‘ë³µ] {unique_key}")
            continue
        seen_keys.add(unique_key)

        # register_date: ì‹œì‘ì¼ì—ì„œ ì¶”ì¶œí•œ YYYY-MM (DB ì €ì¥ìš©)
        register_date = unique_key.split("||")[2]   # "YYYY-MM"

        results.append({
            "ë³‘ì›ëª…": hospital_name,
            "ë³‘ì›íƒ€ì…": hospital_type,
            "ì œëª©": title,
            "ì „ê³µ": specialties,
            "ê³ ìš©í˜•íƒœ": employment_type,
            "ì§€ì—­": location,
            "ë§ˆê°ì¼": deadline,
            "ì‹œì‘ì¼": start_date,
            "register_date": register_date,
            "unique_key": unique_key,
            "ê³µê³ ID": source_id,
            "URL": source_url,
        })
        if len(results) >= TARGET_COUNT:
            break

    return results


def parse_with_selenium(driver, existing):
    """ì…€ë ˆë‹ˆì—„ ì§ì ‘ íŒŒì‹± (fallback)"""
    # ê¸°ì¡´ ê²°ê³¼ì˜ unique_key ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ íŒë‹¨ (ì œëª© ì œì™¸)
    seen_keys = {r["unique_key"] for r in existing}
    results = list(existing)
    title_elems = driver.find_elements(By.CSS_SELECTOR, "span.my-80pqzf")

    for title_elem in title_elems:
        if len(results) >= TARGET_COUNT:
            break
        title = title_elem.text.strip()
        if not title:
            continue
        try:
            col2 = title_elem.find_element(By.XPATH, "./ancestor::button[1]")
            row = col2.find_element(By.XPATH, "..")
            children = row.find_elements(By.XPATH, "./*")
            if len(children) < 4:
                continue
            col1 = children[0]
            col3 = children[2]
            col4 = children[3]

            def safe_text(el, sel):
                try:
                    return el.find_element(By.CSS_SELECTOR, sel).text.strip()
                except Exception:
                    return ""

            hospital_name = safe_text(col1, "span.my-10e3t97")
            hospital_type = safe_text(col1, "span.my-1cqarh6")
            spec_tags = col2.find_elements(By.CSS_SELECTOR, "span.my-1n83qxm")
            specialties = [t.text.strip() for t in spec_tags if t.text.strip()]
            employment_type = safe_text(col3, "span.my-10e3t97")
            location = safe_text(col3, "span.my-1cqarh6")
            col4_ch = col4.find_elements(By.XPATH, "./*")
            deadline = col4_ch[0].text.strip() if len(col4_ch) > 0 else ""
            start_date = col4_ch[1].text.strip() if len(col4_ch) > 1 else ""

            # â”€â”€ ë³µí•© ê³ ìœ  í‚¤ ì¤‘ë³µ ì²´í¬ (ì œëª© ì œì™¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            unique_key = build_unique_key(hospital_name, location, start_date)
            if unique_key in seen_keys:
                print(f"  [SKIP ì¤‘ë³µ] {unique_key}")
                continue
            seen_keys.add(unique_key)

            register_date = unique_key.split("||")[2]

            source_url = ""
            source_id = ""
            try:
                a_elem = col2.find_element(By.XPATH, "ancestor::a[1]")
                href = a_elem.get_attribute("href") or ""
                source_url = href
                m = re.search(r"/recruit/(\d+)", href)
                if m:
                    source_id = m.group(1)
            except Exception:
                pass

            results.append({
                "ë³‘ì›ëª…": hospital_name,
                "ë³‘ì›íƒ€ì…": hospital_type,
                "ì œëª©": title,
                "ì „ê³µ": specialties,
                "ê³ ìš©í˜•íƒœ": employment_type,
                "ì§€ì—­": location,
                "ë§ˆê°ì¼": deadline,
                "ì‹œì‘ì¼": start_date,
                "register_date": register_date,
                "unique_key": unique_key,
                "ê³µê³ ID": source_id,
                "URL": source_url,
            })
        except Exception as e:
            print(f"  âš  Selenium fallback íŒŒì‹± ì˜¤ë¥˜: {e}")
            continue

    return results


def crawl_first_page():
    """ì²« í˜ì´ì§€ ê³µê³  10ê°œ í¬ë¡¤ë§"""
    driver = get_driver()
    results = []
    try:
        login(driver)
        print(f"â–¶ êµ¬ì¸ ê³µê³  í˜ì´ì§€ ì´ë™: {RECRUIT_URL}")
        driver.get(RECRUIT_URL)
        print("â–¶ í˜ì´ì§€ ë Œë”ë§ ëŒ€ê¸° ì¤‘...")
        wait = WebDriverWait(driver, 20)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "span.my-80pqzf")))
        time.sleep(2)
        print("â–¶ BeautifulSoupìœ¼ë¡œ ê³µê³  íŒŒì‹±...")
        results = parse_items_from_source(driver.page_source)
        print(f"  â†’ BeautifulSoup ê²°ê³¼: {len(results)}ê°œ")
        if len(results) < TARGET_COUNT:
            print("â–¶ Selenium fallback íŒŒì‹±...")
            results = parse_with_selenium(driver, results)
            print(f"  â†’ Selenium ê²°ê³¼: {len(results)}ê°œ")
    except Exception as e:
        print(f"  âœ— í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        driver.quit()
    return results



def print_results(results):
    """ê²°ê³¼ í„°ë¯¸ë„ ì¶œë ¥"""
    print("\n" + "=" * 60)
    print(f"  ì´ {len(results)}ê°œ ê³µê³  íŒŒì‹± ì™„ë£Œ")
    print("=" * 60)
    for i, r in enumerate(results, 1):
        print(f"\n[ê³µê³  {i}/{len(results)}]")
        print(f"  âœ… ë³‘ì›ëª…   : {r['ë³‘ì›ëª…']} ({r['ë³‘ì›íƒ€ì…']})")
        print(f"  âœ… ì œëª©     : {r['ì œëª©']}")
        print(f"  âœ… ì „ê³µ     : {', '.join(r['ì „ê³µ']) if r['ì „ê³µ'] else '-'}")
        print(f"  âœ… ê³ ìš©í˜•íƒœ : {r['ê³ ìš©í˜•íƒœ']}")
        print(f"  âœ… ì§€ì—­     : {r['ì§€ì—­']}")
        print(f"  âœ… ë§ˆê°ì¼   : {r['ë§ˆê°ì¼']}")
        print(f"  âœ… ì‹œì‘ì¼   : {r['ì‹œì‘ì¼']}")
        print(f"  âœ… ê³µê³ ID   : {r['ê³µê³ ID'] if r['ê³µê³ ID'] else '-'}")
        print(f"  ğŸ”‘ ê³ ìœ í‚¤   : {r['unique_key']}")


if __name__ == "__main__":
    print("=" * 60)
    print("  ë©”ë””ê²Œì´íŠ¸ êµ¬ì¸ ê³µê³  í¬ë¡¤ëŸ¬ - Phase 3 í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    data = crawl_first_page()
    print_results(data)
    out_path = "C:/medigate_dev/test_crawl_results.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {out_path}")
